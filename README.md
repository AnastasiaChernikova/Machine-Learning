# Machine-Learning

## Task 1
> -  ### Matrix mult
> -  **Deadline:** Feb 19, 2020
> -  **Uploading date:** Mar 4, 2020 
> -  **Link:** <https://github.com/AnastasiaChernikova/Machine-Learning/blob/master/FirstTask.ipynb>

> In this task I created a program that multiplies matrices. 
- Pure way in python:
  1.3647644000000128
- Using Numpy:
  0.0006633000000419997
- Own threading way:
  0.10854268074035645

## Task 2
> -  ### Linear regression
> -  **Deadline:** Feb 26, 2020
> -  **Uploading date:** Mar 31, 2020
> -  **Link:** <https://github.com/AnastasiaChernikova/Machine-Learning/blob/master/SecondTask.ipynb>

> In this task I created a program that work with burrito.csv and real_estate.tsv. I completed task linear regression

> **Data:** 
- burrito.csv <https://github.com/AnastasiaChernikova/Machine-Learning/blob/master/burrito.csv>
- real_estate.tsv <https://github.com/AnastasiaChernikova/Machine-Learning/blob/master/real_estate.tsv>

## Individual task 1
> -  ### Linear regression
> -  **Deadline:** Mar 11, 2020
> -  **Uploading date:** Mar 11, 2020
> -  **Link:** <https://github.com/AnastasiaChernikova/Machine-Learning/blob/master/Induvidual.ipynb>

> In this task I worked with dataset [House Sales in King County, USA](https://www.kaggle.com/harlfoxem/housesalesprediction). This dataset contains house sale prices for King County, which includes Seattle. It includes homes sold between May 2014 and May 2015.

> _Note: Due to a bad internet connection, I asked Yaroslav Andreev to add task. Therefore, there are two contributors in the Induvidual.ipynb_

## Task 3 
> - ### Logistic regression
> - **Deadline:** Mar 25, 2020
> - **Uploading date:** Mar 31, 2020
> - **Link:** <https://github.com/AnastasiaChernikova/Machine-Learning/blob/master/ThirdTask.ipynb>

> In this task I created a program that work with sats.csv and tests.csv. I completed task logistic regression.

> **Data:** 
- sats.csv <https://github.com/AnastasiaChernikova/Machine-Learning/blob/master/sats.csv>
- tests.csv <https://github.com/AnastasiaChernikova/Machine-Learning/blob/master/tests.csv>

## Task 4 
> - ### Neural networks
> - **Deadline:** Apr 1, 2020 
> - **Uploading date:** Apr 2, 2020
> - **Link:** <https://github.com/AnastasiaChernikova/Machine-Learning/blob/master/FourthTask.ipynb>

> In this task I created a program that work with sats.csv and tests.csv. I completed task neural networks. 

> **Data:** 
- sats.csv <https://github.com/AnastasiaChernikova/Machine-Learning/blob/master/sats.csv>
- tests.csv <https://github.com/AnastasiaChernikova/Machine-Learning/blob/master/tests.csv>

## Individual task 2
> - ### Binary logistic regression
> - **Deadline:** Apr 8, 2020  
> - **Uploading date:** Apr 8, 2020 
> - **Link:** <https://github.com/AnastasiaChernikova/Machine-Learning/blob/master/IT2_Iris.ipynb>

> In this task I worked with dataset [Iris Species](https://www.kaggle.com/uciml/iris). The Iris dataset was used in R.A. Fisher's classic 1936 paper, The Use of Multiple Measurements in Taxonomic Problems, and can also be found on the UCI Machine Learning Repository. It includes three iris species with 50 samples each as well as some properties about each flower. One flower species is linearly separable from the other two, but the other two are not linearly separable from each other.

> **Data:** 
- Iris.csv <https://github.com/AnastasiaChernikova/Machine-Learning/blob/master/Iris.csv>
- IT2.jpg <https://github.com/AnastasiaChernikova/Machine-Learning/blob/master/IT2.jpg>
- setosa.jpg <https://github.com/AnastasiaChernikova/Machine-Learning/blob/master/setosa.jpg>
- versicolor.jpg <https://github.com/AnastasiaChernikova/Machine-Learning/blob/master/versicolor.jpg>
- virginica.jpg <https://github.com/AnastasiaChernikova/Machine-Learning/blob/master/virginica.jpg>

## Task 5
> - ### Softmax
> - **Deadline:** Apr 8, 2020  
> - **Uploading date:** Apr 19, 2020 
> - **Link:** <https://github.com/AnastasiaChernikova/Machine-Learning/blob/master/FifthTask.ipynb>

> In this task I worked with dataset [Iris Species](https://www.kaggle.com/uciml/iris). I've added to my previous task Softmax  function

> **Data:** 
- Iris.csv <https://github.com/AnastasiaChernikova/Machine-Learning/blob/master/Iris.csv>

## Task 6
> - ### Regularization & optimization
> - **Learning rate decay**
> - **Deadline:** Apr 15, 2020  
> - **Uploading date:** Apr 20, 2020 
> - **Link:** <https://github.com/AnastasiaChernikova/Machine-Learning/blob/master/SixthTask.ipynb>

> To achieve better performance of your neural network, it is necessary to find the optimal value of learning rate that is not too large and not too small. There are several approaches to find the best learning rate. So in this task i will show work of NN with Learning Rate Decay and Learning Rate

> **Data:** 
- Iris.csv <https://github.com/AnastasiaChernikova/Machine-Learning/blob/master/Iris.csv>


## Task 7
> - ### Text classification
> - **Deadline:** Apr 29, 2020  
> - **Uploading date:** Apr 25, 2020 
> - **Link:** <https://github.com/AnastasiaChernikova/Machine-Learning/blob/master/SeventhTask.ipynb>

> In this task I am working with [20 Newsgroups dataset](https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html) which has become a popular data set for experiments in text applications of machine learning techniques, such as text classification and text clustering.  I have done all the requirements for the task:
> * accuracy_score
> * classification_report
> * confusion_matrix 

## Task 8
> - ### K-means clustering
> - **Deadline:** May 13, 2020  
> - **Uploading date:** May 03, 2020 
> - **Link:** <https://github.com/AnastasiaChernikova/Machine-Learning/blob/master/EighthTask.ipynb>

> In this task I worked with dataset [Iris Species](https://www.kaggle.com/uciml/iris) and realized K-means Clustering.

- Iris.csv <https://github.com/AnastasiaChernikova/Machine-Learning/blob/master/Iris.csv>

## Individual task 3
> - ### Neural networks for multiclass classification
> - **Deadline:** May 13, 2020  
> - **Uploading date:** 
> - **Link:** <...>

> ...

> **Data:** 
